{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON LIRPA VS DECOMON: FULLY CONNECTED MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A: TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import time\n",
    "\n",
    "from numpy.testing import assert_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(\"Notebook run using keras:\", keras.__version__)\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from decomon.models.convert import clone as convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train a Neural Network on a sinusoide\n",
    "\n",
    "The sinusoide funtion is defined on a $[-1 ; 1 ]$ interval. We put a factor in the sinusoide to have several periods of oscillations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 1000)\n",
    "y = np.sin(10 * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate this function by a fully connected network composed of 4 hidden layers of size 100, 100, 20 and 20 respectively. Rectified Linear Units (ReLU) are chosen as activation functions for all the neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(Dense(100, activation=\"linear\", input_dim=1))  # specify the dimension of the input space\n",
    "layers.append(Activation(\"relu\"))\n",
    "layers.append(Dense(100, activation=\"linear\"))\n",
    "layers.append(Activation(\"relu\"))\n",
    "layers.append(Dense(20, activation=\"linear\"))\n",
    "layers.append(Activation(\"relu\"))\n",
    "layers.append(Dense(20, activation=\"linear\"))\n",
    "layers.append(Activation(\"relu\"))\n",
    "layers.append(Dense(1, activation=\"linear\"))\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we specify the optimization method and the metric, in this case a classical Means Square Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=32, shuffle=True, epochs=100, verbose=0)\n",
    "# verbose=0 removes the printing along the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.hidden_0 = nn.Linear(1, 100)  # input_dim = 1; output_dim = 100\n",
    "        self.hidden_1 = nn.Linear(100, 100)\n",
    "        self.hidden_2 = nn.Linear(100, 20)\n",
    "        self.hidden_3 = nn.Linear(20, 20)\n",
    "        self.hidden_4 = nn.Linear(1, 20)\n",
    "\n",
    "        self.layers = [self.hidden_0, self.hidden_1, self.hidden_2, self.hidden_3, self.hidden_4]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden_4(x)\n",
    "        return x\n",
    "        # x = x.view(-1, 128)\n",
    "        # return x\n",
    "\n",
    "    def reset_weights(self, model):\n",
    "        layers = model.layers\n",
    "        index = 0\n",
    "        for layer_keras in layers:\n",
    "            if len(layer_keras.get_weights()):\n",
    "                print(layer_keras.name)\n",
    "                layer_torch = self.layers[index]\n",
    "                weights = layer_keras.get_weights()\n",
    "                layer_torch.weight.data = torch.from_numpy(np.transpose(weights[0]))\n",
    "                layer_torch.bias.data = torch.from_numpy(np.transpose(weights[1]))\n",
    "                index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch = NeuralNet()\n",
    "model_torch.reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch.reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomon_model_0 = convert(model, method=\"crown-ibp\", ibp=True, forward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.22840400000000116 + 0.000354999999998995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our model into a decomon model:\n",
    "decomon_model_1 = convert(model, method=\"crown\", ibp=True, forward=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x[:, None]).float().to(\"cpu\")\n",
    "y_pred_torch = model_torch(x_train_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_torch = model_torch(x_train_tensor).cpu().detach().numpy()\n",
    "y_pred_keras = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(y_pred_keras, y_pred_torch, decimal=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y_pred_torch, \"x\")\n",
    "plt.plot(x, y_pred_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTO LIRPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the intervals\n",
    "\n",
    "\n",
    "def get_range_box_comparison(method, model_decomon_1, model_torch, x_min=x.min(), x_max=x.max(), n_split=10):\n",
    "    alpha = np.linspace(0, 1, n_split + 1)\n",
    "    x_samples = (1 - alpha) * x_min + alpha * x_max\n",
    "    X_min = x_samples[:-1][:, None]\n",
    "    X_max = x_samples[1:][:, None]\n",
    "    X_lirpa_ = (X_min + X_max) / 2.0\n",
    "    eps = 0.5 * (x_max - x_min) / n_split\n",
    "\n",
    "    # convert X_lirpa into a pytorch tensor\n",
    "    X_lirpa = torch.from_numpy(X_lirpa_).float().to(\"cpu\")\n",
    "    import time\n",
    "\n",
    "    start_time_torch = time.process_time()\n",
    "    model_lirpa = BoundedModule(model_torch, X_lirpa)\n",
    "    ptb = PerturbationLpNorm(norm=np.inf, eps=eps)\n",
    "    input_lirpa = BoundedTensor(X_lirpa, ptb)\n",
    "\n",
    "    lb, ub = model_lirpa.compute_bounds(x=(input_lirpa,), method=method)\n",
    "\n",
    "    lb_ = lb.cpu().detach().numpy()\n",
    "    ub_ = ub.cpu().detach().numpy()\n",
    "    end_time_torch = time.process_time()\n",
    "\n",
    "    start_time_decomon = time.process_time()\n",
    "    boxes = np.concatenate([X_min[:, None], X_max[:, None]], 1)\n",
    "    upper_, lower_ = model_decomon_1.predict(boxes)\n",
    "    end_time_decomon = time.process_time()\n",
    "\n",
    "    print(end_time_decomon - start_time_decomon, end_time_torch - start_time_torch)\n",
    "\n",
    "    # upper_0, lower_0 = get_range_noise(model_decomon_0, X_lirpa_, eps, p=np.inf)\n",
    "    # upper_, lower_ = get_range_box(model_decomon_1, X_min, X_max, fast=True)\n",
    "    # upper_ = np.minimum(upper_0, upper_0)\n",
    "    # lower_ = np.maximum(lower_1, lower_1)\n",
    "\n",
    "    return X_lirpa_, model.predict(X_lirpa_), lb_, ub_, lower_, upper_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples, y_samples, lb_p_0, ub_p_0, lb_t_0, ub_t_0 = get_range_box_comparison(\n",
    "    \"IBP+backward\", decomon_model_0, model_torch, n_split=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples, y_samples, lb_p_1, ub_p_1, lb_t_1, ub_t_1 = get_range_box_comparison(\n",
    "    \"crown\", decomon_model_1, model_torch, n_split=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(ub_p_0, ub_t_0, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(lb_p_0, lb_t_0, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(lb_p_1, lb_t_1, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(ub_p_1, ub_t_1, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
