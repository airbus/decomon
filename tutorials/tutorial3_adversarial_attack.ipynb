{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DECOMON tutorial #3\n",
    " \n",
    "_**Local Robustness to Adversarial Attacks for classification tasks**_\n",
    "\n",
    "<decomonlinks>\n",
    "<p align=\"center\">\n",
    "  <img src=\"data/decomon.jpg\" alt=\"Decomon!\" width=\"100\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "- &#x1F4DA; <a href=\"https://airbus.github.io/decomon\"> Documentation </a>\n",
    "- <a href=\"https://github.com/airbus/decomon\"> Github </a>\n",
    "- <a href=\"https://airbus.github.io/decomon/main/tutorials.html \"> Tutorials </a>\n",
    "    \n",
    "_Author: [Melanie DUCOFFE](https://fr.linkedin.com/in/m%C3%A9lanie-ducoffe-bbb53165)_\n",
    "</decomonlinks>\n",
    "\n",
    "After training a model, we want to make sure that the model will give the same output for any images \"close\" to the initial one, showing some robustness to perturbation. \n",
    "\n",
    "In this notebook, we start from a classifier built on MNIST dataset that given a hand-written digit as input will predict the digit. This will be the first part of the notebook.\n",
    "\n",
    "<img src=\"./data/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png\" alt=\"examples of hand-written digit\" width=\"600\"/>\n",
    "\n",
    "In the second part of the notebook, we will investigate the robustness of this model to unstructured modification of the input space: adversarial attacks. For this kind of attacks, **we vary the magnitude of the perturbation of the initial image** and want to assess that despite this noise, the classifier's prediction remain unchanged.\n",
    "\n",
    "<img src=\"./data/illustration_adv_attacks.jpeg\" alt=\"examples of perturbated images\" width=\"600\"/>\n",
    "\n",
    "What we will show is the use of decomon module to assess the robustness of the prediction towards noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When running this notebook on Colab, we need to install *decomon* if on Colab. \n",
    "- If you run this notebook locally, do it inside the environment in which you [installed *decomon*](https://airbus.github.io/decomon/main/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import sys  # noqa: avoid having this import removed by pycln\n",
    "\n",
    "    # install dev version for dev doc, or release version for release doc\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install git+https://github.com/airbus/decomon@keras3#egg=decomon\n",
    "    !{sys.executable} -m pip uninstall -y keras keras-nightly\n",
    "    !{sys.executable} -m pip install keras-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import os.path\n",
    "import pickle as pkl\n",
    "import time\n",
    "from contextlib import closing\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, Dense, Input\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images\n",
    "\n",
    "We load MNIST data from keras datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "y_train = keras.utils.to_categorical(y_train_)\n",
    "y_test = keras.utils.to_categorical(y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the model (classifier for MNIST images)\n",
    "\n",
    "For the model, we use a small fully connected network. It is made of 6 layers with 100 units each and ReLU activation functions. **Decomon** is compatible with a large set of Keras layers, so do not hesitate to modify the architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=784))\n",
    "model.add(Activation(\"relu\"))  # Decomon deduces tighter bound when splitting Dense and activation\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, shuffle=True, validation_split=0.2, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we see that the assessment of performance of the model on data that was not seen during training shows pretty good results: around 0.97 (maximum value is 1). It means that out of 100 images, the model was able to guess the correct digit for 97 images. But how can we guarantee that we will get this performance for images different from the ones in the test dataset? \n",
    "\n",
    "- If we perturbate a \"little\" an image that was well predicted, will the model stay correct? \n",
    "- Up to which perturbation?  \n",
    "- Can we guarantee that the model will output the same digit for a given perturbation? \n",
    "\n",
    "This is where decomon comes in. \n",
    "\n",
    "<img src=\"./data/decomon.jpg\" alt=\"Decomon!\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying decomon for local robustness to misclassification\n",
    "\n",
    "In this section, we detail how to prove local robustness to misclassification. Misclassification can be studied with the global optimisation of a function f:\n",
    "\n",
    "$$ f(x; \\Omega) = \\max_{z\\in \\Omega} \\text{NN}_{j\\not= i}(z) - \\text{NN}_i(z)\\;\\; \\text{s.t}\\;\\; i = argmax\\;\\text{NN}(x)$$\n",
    "\n",
    "If the maximum of f is **negative**, this means that whathever the input sample from the domain, the value outputs by the neural network NN for class i will always be greater than the value output for another class. Hence, there will be no misclassification possible. This is **adversarial robustness**.\n",
    "\n",
    "<img src=\"./data/tuto_3_formal_robustness.png\" alt=\"Decomon!\" width=\"700\"/>\n",
    "\n",
    "In that order, we will use the [decomon](https://gheprivate.intra.corp/CRT-DataScience/decomon/tree/master/decomon) library. Decomon combines several optimization trick, including linear relaxation\n",
    "to get state-of-the-art outer approximation.\n",
    "\n",
    "To use **decomon** for **adversarial robustness** we first need the following imports:\n",
    "+ *from decomon.models import clone*: to convert our current Keras model into another neural network nn_model. nn_model shares the same weights but outputs information that will be used to derive our formal bounds. For a sake of clarity, how to get such bounds is hidden to the user\n",
    "\n",
    "+ *from decomon import get_adv_box*: a genereric method to get an upper bound of the funtion f described previously. If the returned value is negative, then we formally assess the robustness to misclassification.\n",
    "\n",
    "+ *from decomon import check_adv_box*: a generic method that computes the maximum of a lower bound of f. Eventually if this value is positive, it demonstrates that the function f takes positive value. It results that a positive value formally proves the existence of misclassification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decomon import get_adv_box\n",
    "from decomon.models import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computational efficiency, we convert the model into its decomon version once and for all.\n",
    "Note that the decomon method will work on the non-converted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomon_model = clone(model, method=\"crown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We offer an interactive visualisation of the basic adversarial robustness method from decomon **get_adv_box**. We randomly choose 10 test images use **get_adv_box** to assess their robustness to misclassification pixel perturbations. The magnitude of the noise on each pixel is independent and bounded by the value of the variable epsilon. The user can reset the examples and vary the noise amplitude.\n",
    "\n",
    "Note one of the main advantage of decomon: **we can assess robustness on batches of data!**\n",
    "\n",
    "Circled in <span style=\"color:green\">green</span> are examples that are formally assessed to be robust, <span style=\"color:orange\">orange</span> examples that could be robust and  <span style=\"color:red\">red</span> examples that are formally non robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame(epsilon, reset=0, filename=\".hidden_index.pkl\"):\n",
    "    n_cols = 5\n",
    "    n_rows = 2\n",
    "    n_samples = n_cols * n_rows\n",
    "    if reset:\n",
    "        index = np.random.permutation(len(x_test))[:n_samples]\n",
    "\n",
    "        with closing(open(filename, \"wb\")) as f:\n",
    "            pkl.dump(index, f)\n",
    "        # save data\n",
    "    else:\n",
    "        # check that file exists\n",
    "\n",
    "        if os.path.isfile(filename):\n",
    "            with closing(open(filename, \"rb\")) as f:\n",
    "                index = pkl.load(f)\n",
    "        else:\n",
    "            index = np.arange(n_samples)\n",
    "            with closing(open(filename, \"wb\")) as f:\n",
    "                pkl.dump(index, f)\n",
    "    # x = np.concatenate([x_test[0:1]]*10, 0)\n",
    "    x = x_test[index]\n",
    "\n",
    "    x_min = np.maximum(x - epsilon, 0)\n",
    "    x_max = np.minimum(x + epsilon, 1)\n",
    "\n",
    "    n_cols = 5\n",
    "    n_rows = 2\n",
    "    fig, axs = plt.subplots(n_rows, n_cols)\n",
    "\n",
    "    fig.set_figheight(n_rows * fig.get_figheight())\n",
    "    fig.set_figwidth(n_cols * fig.get_figwidth())\n",
    "    plt.subplots_adjust(hspace=0.2)  # increase vertical separation\n",
    "    axs_seq = axs.ravel()\n",
    "\n",
    "    source_label = y_test[index]\n",
    "\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    upper = get_adv_box(decomon_model, x_min, x_max, source_labels=source_label, n_sub_boxes=1)\n",
    "    # lower = check_adv_box(decomon_model, x_min, x_max, source_labels=source_label, n_sub_boxes=1)\n",
    "    lower = 0.0 * upper - 1\n",
    "    end_time = time.process_time()\n",
    "\n",
    "    count = 0\n",
    "    time.sleep(1)\n",
    "    r_time = \"{:.2f}\".format(end_time - start_time)\n",
    "    fig.suptitle(\n",
    "        \"Formal Robustness to Adversarial Examples with eps={} running in {} seconds\".format(epsilon, r_time),\n",
    "        fontsize=16,\n",
    "    )\n",
    "    for i in range(n_cols):\n",
    "        for j in range(n_rows):\n",
    "            ax = axs[j, i]\n",
    "            ax.imshow(x[count].reshape((28, 28)), cmap=\"Greys\")\n",
    "            robust = \"ROBUST\"\n",
    "            if lower[count] >= 0:\n",
    "                if upper[count] <= 0:\n",
    "                    import pdb\n",
    "\n",
    "                    pdb.set_trace()\n",
    "                color = \"red\"\n",
    "                robust = \"NON ROBUST\"\n",
    "            elif upper[count] < 0:\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"orange\"\n",
    "                robust = \"MAYBE ROBUST\"\n",
    "\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            # Create a Rectangle patch\n",
    "            rect = patches.Rectangle((0, 0), 27, 27, linewidth=3, edgecolor=color, facecolor=\"none\")\n",
    "            ax.add_patch(rect)\n",
    "            ax.set_title(robust)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "interact(\n",
    "    frame,\n",
    "    epsilon=widgets.FloatSlider(\n",
    "        value=0.0,\n",
    "        min=0.0,\n",
    "        max=25.0 / 255.0,\n",
    "        step=0.0001,\n",
    "        continuous_update=False,\n",
    "        readout_format=\".4f\",\n",
    "    ),\n",
    "    reset=widgets.IntSlider(value=0.0, min=0, max=1, step=1, continuous_update=False),\n",
    "    fast=widgets.IntSlider(value=1.0, min=0, max=1, step=1, continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained previously, the method **get_adv_box** output a constant upper bound that is valid on the whole domain.\n",
    "Sometimes, this bound can be too lose and needs to be refined by splitting the input domain into sub domains.\n",
    "Several heuristics are possible and you are free to develop your own or take an existing one of the shelf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the verification: bounding adversarial robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the verification studied in the previous tutorials 1 & 2, **adversarial robustness** relies on the largest difference taken by two outputs.\n",
    "Instead of bouding the output of the neural network, we want to bound the function that measures **adversarial robustness**, expressed hereafter:\n",
    "$$ f(x; \\Omega) = \\max_{z\\in \\Omega} \\text{NN}_{j\\not= i}(z) - \\text{NN}_i(z)\\;\\; \\text{s.t}\\;\\; i = argmax\\;\\text{NN}(x)$$\n",
    "\n",
    "In this section, we adapt the previous cells of the notebook to optimize formal methods for adversarial robustness. In that aim, we add another input to our formal method: a matrix **C** that encompasses the information. C is a triangular matrix as the following:\n",
    "$$\n",
    "C_{p,q} = \\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        1 & \\mbox{if } \\ p = \\ q \\not= \\ i \\\\\n",
    "        0 & \\mbox{if } \\ p = \\ q = \\ i \\\\\n",
    "        -1 & \\mbox{if } \\ p \\not= \\ q  \\mbox{ and } \\ q = \\ i \\\\\n",
    "        -1 & \\mbox{else.}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "With the next cells, we can observe by varying the radius of the perturbation that the new formal method outperforms the previous one and sometimes allows to demonstrate the **adversarial robustness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Input((10, 10))\n",
    "decomon_model_adv = clone(model, back_bounds=[C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame(eps=0.1, n_sub_boxes=1):\n",
    "    # select 10 images\n",
    "    indices = np.array([np.where(y_test_ == i)[0][0] for i in range(5)])\n",
    "    images = x_test[indices]\n",
    "    # we create a matrix that stores the information l_j - l_i\n",
    "    C = np.diag([1.0] * 10)[None] - y_test[indices, :, None]\n",
    "\n",
    "    adv_crown = get_adv_box(\n",
    "        decomon_model, images - eps, images + eps, source_labels=y_test[indices], n_sub_boxes=n_sub_boxes\n",
    "    )\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    adv_better = get_adv_box(\n",
    "        decomon_model_adv, images - eps, images + eps, source_labels=y_test[indices], n_sub_boxes=n_sub_boxes\n",
    "    )\n",
    "\n",
    "    end_time = time.process_time()\n",
    "\n",
    "    n_rows = 2\n",
    "    n_cols = 5\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols)\n",
    "\n",
    "    fig.set_figheight(n_rows * fig.get_figheight())\n",
    "    fig.set_figwidth(n_cols * fig.get_figwidth())\n",
    "    plt.subplots_adjust(hspace=0.2)  # increase vertical separation\n",
    "    axs_seq = axs.ravel()\n",
    "\n",
    "    count = 0\n",
    "    time.sleep(1)\n",
    "    r_time = \"{:.2f}\".format(end_time - start_time)\n",
    "    fig.suptitle(\n",
    "        \"Formal Robustness to Adversarial Examples with eps={} (n_splits={}) running in {} seconds\".format(\n",
    "            eps, n_sub_boxes, r_time\n",
    "        ),\n",
    "        fontsize=16,\n",
    "    )\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            ax = axs[i, j]\n",
    "            ax.imshow(images[j].reshape((28, 28)), cmap=\"Greys\")\n",
    "\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # Create a Rectangle patch\n",
    "            if i == 0:\n",
    "                if adv_crown[j] >= 0:\n",
    "                    color = \"orange\"\n",
    "                else:\n",
    "                    color = \"green\"\n",
    "            else:\n",
    "                if adv_better[j] > 0:\n",
    "                    color = \"orange\"\n",
    "                else:\n",
    "                    color = \"green\"\n",
    "            rect = patches.Rectangle((0, 0), 27, 27, linewidth=3, edgecolor=color, facecolor=\"none\")\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "\n",
    "interact(\n",
    "    frame,\n",
    "    eps=widgets.FloatSlider(\n",
    "        value=0.0103,\n",
    "        min=0.0,\n",
    "        max=10.0 / 255.0,\n",
    "        step=0.0001,\n",
    "        continuous_update=False,\n",
    "        readout_format=\".4f\",\n",
    "    ),\n",
    "    n_sub_boxes=widgets.IntSlider(value=1.0, min=1, max=20, step=1, continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model will be 0 for the groundtruth label.\n",
    "If every other outputs have negative values, this implies that the prediction is robust to misclassification in the considered input region.\n",
    "The first rown contains the first formal method, while the second row is its optimized version. We observe that the optimized version may demonstrate robustness while the original formal method cannot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
