{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECOMON tutorial #3 \n",
    "## Local Robustness to Adversarial Attacks for classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "After training a model, we want to make sure that the model will give the same output for any images \"close\" to the initial one, showing some robustness to perturbation. \n",
    "\n",
    "In this notebook, we start from a classifier built on MNIST dataset that given a hand-written digit as input will predict the digit. This will be the first part of the notebook.\n",
    "\n",
    "<img src=\"./data/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png\" alt=\"examples of hand-written digit\" width=\"600\"/>\n",
    "\n",
    "In the second part of the notebook, we will investigate the robustness of this model to unstructured modification of the input space: adversarial attacks. For this kind of attacks, **we vary the magnitude of the perturbation of the initial image** and want to assess that despite this noise, the classifier's prediction remain unchanged.\n",
    "\n",
    "<img src=\"./data/illustration_adv_attacks.jpeg\" alt=\"examples of hand-written digit\" width=\"600\"/>\n",
    "\n",
    "What we will show is the use of decomon module to assess the robustness of the prediction towards noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The notebook\n",
    "\n",
    "###Â imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipykernel.pylab.backend_inline import flush_figures\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os.path\n",
    "import os\n",
    "import pickle as pkl\n",
    "from contextlib import closing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load images\n",
    "\n",
    "We load MNIST data from keras datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "y_train = keras.utils.to_categorical(y_train_)\n",
    "y_test = keras.utils.to_categorical(y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn the model (classifier for MNIST images)\n",
    "\n",
    "For the model, we use a small fully connected network. It is made of 6 layers with 100 units each and ReLU activation functions. **Decomon** is compatible with a large set of Keras layers, so do not hesitate to modify the architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=784))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4893 - acc: 0.8560 - val_loss: 0.1391 - val_acc: 0.9596\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 892us/step - loss: 0.1265 - acc: 0.9627 - val_loss: 0.1120 - val_acc: 0.9661\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 876us/step - loss: 0.0839 - acc: 0.9752 - val_loss: 0.1017 - val_acc: 0.9707\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 878us/step - loss: 0.0571 - acc: 0.9830 - val_loss: 0.0932 - val_acc: 0.9725\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 877us/step - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0986 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x166de0650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam', 'categorical_crossentropy', metrics='acc')\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, shuffle=True, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 888us/step - loss: 0.0888 - acc: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08877523988485336, 0.973800003528595]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we see that the assessment of performance of the model on data that was not seen during training shows pretty good results: around 0.97 (maximum value is 1). It means that out of 100 images, the model was able to guess the correct digit for 97 images. But how can we guarantee that we will get this performance for images different from the ones in the test dataset? \n",
    "\n",
    "- If we perturbate a \"little\" an image that was well predicted, will the model stay correct? \n",
    "- Up to which perturbation?  \n",
    "- Can we guarantee that the model will output the same digit for a given perturbation? \n",
    "\n",
    "This is where decomon comes in. \n",
    "\n",
    "<img src=\"./data/decomon.jpg\" alt=\"Decomon!\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Decomon for Local Robustness to misclassification\n",
    "\n",
    "In this section, we detail how to prove local robustness to misclassification. Misclassification can be studied with the global optimisation of a function f:\n",
    "\n",
    "$$ f(x; \\Omega) = \\max_{z\\in \\Omega} \\text{NN}_{j\\not= i}(z) - \\text{NN}_i(z)\\;\\; \\text{s.t}\\;\\; i = argmax\\;\\text{NN}(x)$$\n",
    "\n",
    "If the maximum of f is **negative**, this means that whathever the input sample from the domain, the value outputs by the neural network NN for class i will always be greater than the value output for another class. Hence, there will be no misclassification possible. This is **adversarial robustness**.\n",
    "\n",
    "<img src=\"./data/tuto_3_formal_robustness.png\" alt=\"Decomon!\" width=\"400\"/>\n",
    "\n",
    "In that order, we will use the [decomon](https://gheprivate.intra.corp/CRT-DataScience/decomon/tree/master/decomon) library. Decomon combines several optimization trick, including linear relaxation\n",
    "to get state-of-the-art outer approximation.\n",
    "\n",
    "To use **decomon** for **adversarial robustness** we first need the following imports:\n",
    "+ *from decomon.models import convert*: to convert our current Keras model into another neural network nn_model. nn_model will output the same prediction that our model and adds extra information that will be used to derive our formal bounds. For a sake of clarity, how to get such bounds is hidden to the user\n",
    "\n",
    "+ *from decomon import get_adv_box*: a genereric method to get an upper bound of the funtion f described previously. If the returned value is negative, then we formally assess the robustness to misclassification.\n",
    "\n",
    "+ *from decomon import check_adv_box*: a generic method that computes the maximum of a lower bound of f. Eventually if this value is positive, it demonstrates that the function f takes positive value. It results that a positive value formally proves the existence of misclassification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decomon\n",
    "from decomon.models import convert\n",
    "from decomon import get_adv_box, get_upper_box, get_lower_box, check_adv_box, get_upper_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computational efficiency, we convert the model into its decomon version once and for all.\n",
    "Note that the decomon method will work on the non-converted model. To obtain more refined guarantees, we activate an option denoted **forward**. You can speed up the method by removing this option in the convert method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 784) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 784), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 784) for input KerasTensor(type_spec=TensorSpec(shape=(None, 784), dtype=tf.float32, name='input_17'), name='input_17', description=\"created by layer 'input_17'\"), but it was called on an input with incompatible shape (None, 2, 784).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    ../decomon/backward_layers/backward_layers.py:52 call  *\n        x = self.layer.call_linear(x_)\n    ../decomon/layers/decomon_layers.py:653 call_linear  *\n        y, x_0, u_c, w_u, b_u, l_c, w_l, b_l = inputs[:8]\n\n    ValueError: not enough values to unpack (expected 8, got 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-faf9639967d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecomon_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Code/open_sourcing/Airbus/decomon/decomon/models/decomon_sequential.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, input_tensors, layer_fn, dc_decomp, convex_domain, mode, slope_backward, IBP, forward, linearize, finetune, options)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBackward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mmodel_monotonic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_monotonic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslope_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0minput_shape_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/open_sourcing/Airbus/decomon/decomon/models/decomon_sequential.py\u001b[0m in \u001b[0;36mget_backward\u001b[0;34m(model, back_bounds, slope, input_dim, options)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0mback_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m     \u001b[0mback_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_backward_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/open_sourcing/Airbus/decomon/decomon/models/decomon_sequential.py\u001b[0m in \u001b[0;36mget_backward_model\u001b[0;34m(model, back_bounds, input_model, slope, options)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                     \u001b[0mdico_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                     \u001b[0mdico_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                     \u001b[0mdico_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/formal/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/formal/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/formal/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/formal/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/formal/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    ../decomon/backward_layers/backward_layers.py:52 call  *\n        x = self.layer.call_linear(x_)\n    ../decomon/layers/decomon_layers.py:653 call_linear  *\n        y, x_0, u_c, w_u, b_u, l_c, w_l, b_l = inputs[:8]\n\n    ValueError: not enough values to unpack (expected 8, got 5)\n"
     ]
    }
   ],
   "source": [
    "decomon_model = convert(model, forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We offer an interactive visualisation of the basic adversarial robustness method from decomon **get_adv_upper**. We randomly choose 10 test images use **get_adv_upper** to assess their robustness to misclassification pixel perturbations. The magnitude of the noise on each pixel is independent and bounded by the value of the variable epsilon. The user can reset the examples and vary the noise amplitude.\n",
    "\n",
    "Note one of the main advantage of decomon: **we can assess robustness on batches of data!**\n",
    "\n",
    "Circled in <span style=\"color:green\">green</span> are examples that are formally assessed to be robust, <span style=\"color:orange\">orange</span> examples that could be robust and  <span style=\"color:red\">red</span> examples that are formally non robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c17a2000ad4c9fa8d82b24da74f416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='epsilon', max=0.09803921568â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.frame(epsilon, reset=0, filename='./data/.hidden_index.pkl')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frame(epsilon, reset=0, filename='./data/.hidden_index.pkl'):\n",
    "    n_cols = 5\n",
    "    n_rows = 2\n",
    "    n_samples = n_cols*n_rows\n",
    "    if reset:\n",
    "        index = np.random.permutation(len(x_test))[:n_samples]\n",
    "        \n",
    "        with closing(open(filename, 'wb')) as f:\n",
    "            pkl.dump(index, f)\n",
    "        # save data\n",
    "    else:\n",
    "        # check that file exists\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            with closing(open(filename, 'rb')) as f:\n",
    "                index = pkl.load(f)\n",
    "        else:  \n",
    "            index = np.arange(n_samples)\n",
    "            with closing(open(filename, 'wb')) as f:\n",
    "                pkl.dump(index, f)\n",
    "    #x = np.concatenate([x_test[0:1]]*10, 0)\n",
    "    x = x_test[index]\n",
    "\n",
    "    x_min = np.maximum(x - epsilon, 0)\n",
    "    x_max = np.minimum(x + epsilon, 1)\n",
    "\n",
    "    n_cols = 5\n",
    "    n_rows = 2\n",
    "    fig, axs = plt.subplots(n_rows, n_cols)\n",
    "    \n",
    "    fig.set_figheight(n_rows*fig.get_figheight())\n",
    "    fig.set_figwidth(n_cols*fig.get_figwidth())\n",
    "    plt.subplots_adjust(hspace=0.2)  # increase vertical separation\n",
    "    axs_seq = axs.ravel()\n",
    "\n",
    "    source_label = y_test[index]\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "    upper = get_adv_box(decomon_model, x_min, x_max, source_labels=source_label)\n",
    "    lower = -check_adv_box(decomon_model, x_min, x_max, source_labels=source_label)\n",
    "    \n",
    "    end_time = time.process_time()\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    time.sleep(1)\n",
    "    r_time = \"{:.2f}\".format(end_time - start_time)\n",
    "    fig.suptitle('Formal Robustness to Adversarial Examples with eps={} running in {} seconds'.format(epsilon, r_time), fontsize=16)\n",
    "    for i in range(n_cols):\n",
    "        for j in range(n_rows):\n",
    "\n",
    "            ax= axs[j, i]\n",
    "            ax.imshow(x[count].reshape((28,28)), cmap='Greys')\n",
    "            robust='ROBUST'\n",
    "            if lower[count]>=0:\n",
    "                if upper[count]<=0:\n",
    "                    import pdb; pdb.set_trace()\n",
    "                color='red'\n",
    "                robust='NON ROBUST'\n",
    "            elif upper[count]<0:\n",
    "                color='green'\n",
    "            else:\n",
    "                color='orange'\n",
    "                robust='MAYBE ROBUST'\n",
    "        \n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            # Create a Rectangle patch\n",
    "            rect = patches.Rectangle((0,0),27,27,linewidth=3,edgecolor=color,facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.set_title(robust)\n",
    "            count+=1\n",
    "    \n",
    "            \n",
    "interact(frame, epsilon = widgets.FloatSlider(value=0.,\n",
    "                                               min=0.,\n",
    "                                               max=25./255.,\n",
    "                                               step=0.0001, continuous_update=False, readout_format='.4f',),\n",
    "         reset = widgets.IntSlider(value=0.,\n",
    "                                               min=0,\n",
    "                                               max=1,\n",
    "                                               step=1, continuous_update=False),\n",
    "         fast = widgets.IntSlider(value=1.,\n",
    "                                               min=0,\n",
    "                                               max=1,\n",
    "                                               step=1, continuous_update=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained previously, the method **get_adv_upper** output a constant upper bound that is valid on the whole domain.\n",
    "Sometimes, this bound can be too lose and needs to be refined by splitting the input domain into sub domains.\n",
    "Several heuristics are possible and you are free to develop your own or take an existing one of the shelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
