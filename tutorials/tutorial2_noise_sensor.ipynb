{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DECOMON tutorial #2\n",
    " \n",
    "_**Local Robustness to sensor noise for Regression**_\n",
    "\n",
    "<decomonlinks>\n",
    "<p align=\"center\">\n",
    "  <img src=\"data/decomon.jpg\" alt=\"Decomon!\" width=\"100\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "- &#x1F4DA; <a href=\"https://airbus.github.io/decomon\"> Documentation </a>\n",
    "- <a href=\"https://github.com/airbus/decomon\"> Github </a>\n",
    "- <a href=\"https://airbus.github.io/decomon/main/tutorials.html \"> Tutorials </a>\n",
    "    \n",
    "_Author: [Melanie DUCOFFE](https://fr.linkedin.com/in/m%C3%A9lanie-ducoffe-bbb53165)_\n",
    "</decomonlinks>\n",
    "\n",
    "Embedding simulation models developed during the design\n",
    "of a platform opens a lot of potential new functionalities\n",
    "but requires additional certification. Usually, these models require too much computing power, take too much time to run\n",
    "so we need to build an approximation of these models that can\n",
    "be compatible with operational constraints, hardware constraints, and real-time constraints. Also, we need to prove that\n",
    "the decisions made by the system using the surrogate model\n",
    "instead of the reference one will be safe.\n",
    "\n",
    "A first assessment that can be performed is the **robustness of the prediction given sensor noise**: demonstrating that despite sensor noise, the neural network prediction remains consistent.\n",
    "\n",
    "Local Robustness to **sensoir noise** can be performed efficiently thanks to formal robustness. In this notebook, we demonstrate how to derive deterministic upper and lower bounds of the output prediction of a neural network in the vicinity of a test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial need decomon to be installed as well as [pandas](https://pandas.pydata.org/).\n",
    "\n",
    "- When running this notebook on Colab, we need to install *decomon* if on Colab. \n",
    "- If you run this notebook locally, do it inside the environment in which you [installed *decomon*](https://airbus.github.io/decomon/main/install.html) and [pandas](https://pandas.pydata.org/docs/getting_started/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import sys  # noqa: avoid having this import removed by pycln\n",
    "\n",
    "    # install dev version for dev doc, or release version for release doc\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install git+https://github.com/airbus/decomon@keras3#egg=decomon\n",
    "    # install desired backend (by default tensorflow)\n",
    "    !{sys.executable} -m pip install \"tensorflow>=2.15\"\n",
    "    # ensure having keras 3 and not keras 2.15\n",
    "    !{sys.executable} -m pip uninstall -y keras\n",
    "    !{sys.executable} -m pip install \"keras>=3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example: Electric Motor Temperature\n",
    "\n",
    "We will demonstrate how to perform **Local Robustness to sensoir noise** on a surrogate toy case.\n",
    "A neural network is trained to infer the temperature of a permanent-magnet synchronous motor ([PMSM](https://en.wikipedia.org/wiki/Synchronous_motor#Permanent-magnet_motors) ) given correlated features:\n",
    "\n",
    "+ ambiant: Ambient temperature as measured by a thermal sensor located closely to the stator.\n",
    "+ coolant: Coolant temperature. The motor is water cooled. Measurement is taken at outflow.\n",
    "+ u_d: Voltage d-component\n",
    "+ u_q: Voltage q-component\n",
    "+ motor_speed\n",
    "+ torque: Torque induced by current.\n",
    "+ i_d: Current d-component\n",
    "+ i_q: Current q-component\n",
    "\n",
    "\n",
    "The recorded temperature refers to the Permanent Magnet surface temperature (pm) representing the rotor temperature. This was measured with an infrared with 140 hrs recordings. Distinctive sessions are identified with \"profile_id\". You will find additional information in the [official data repository](https://www.kaggle.com/wkirgsn/electric-motor-temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset locally\n",
    "\n",
    "To download the data you need a [Kaggle](https://www.kaggle.com) account. Then you can download the dataset by clicking on the \"download\" button on the [official data repository](https://www.kaggle.com/wkirgsn/electric-motor-temperature). Unzip the file in the same directory as this notebook.\n",
    "\n",
    "\n",
    "You can also use the method described for Binder and Colab below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset on Binder or Colab \n",
    "\n",
    "If you run this notebook on Binderhub or Colab, follow this process to get the dataset:\n",
    "\n",
    "- Create a [Kaggle]() account.\n",
    "- Download a Kaggle API token by clicking on \"Create New API Token\" on your account page. You will get a kaggle.json file with the needed credentials. \n",
    "- Upload this kaggle.jon file on Binderhub or Colab. (You need to click on the directory icon on the left, and then on the upload button.)\n",
    "- Then run the next cell which will\n",
    "    - put the token at the right place with the right accesses,\n",
    "    - use the kaggle api to download the dataset,\n",
    "    - unzip it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "on_colab = \"google.colab\" in str(get_ipython())  # running on colab?\n",
    "on_binder = socket.gethostname().startswith(\"jupyter-\")  # running on binder? (not 100% sure but rather robust)\n",
    "\n",
    "if on_colab or on_binder:\n",
    "    # First of all, upload your kaggle api token kaggle.json\n",
    "    ! mkdir ~/.kaggle\n",
    "    ! mv kaggle.json ~/.kaggle\n",
    "    ! chmod 600 ~/.kaggle/kaggle.json\n",
    "    ! kaggle datasets download -d wkirgsn/electric-motor-temperature\n",
    "    ! unzip -o electric-motor-temperature.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: prepare the data and the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from numpy.testing import assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of context, we display statistical informations of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"measures_v2.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to dinstinguish our target (output, *pm*) and our features (inputs). We build the train and test set with a 80/20 ratio\n",
    "given the *profile_id*. Indeed we don't want to be biased by the recording session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"pm\"]  # column \"pm\" is our target\n",
    "X = data.drop([\"pm\"], axis=1)  # the other columns are our features\n",
    "\n",
    "# sort given profile_id and split into train and test (80% of the sessions will be used for training the NN)\n",
    "index = []\n",
    "for i in range(X[\"profile_id\"].min(), X[\"profile_id\"].max()):\n",
    "    if i in X[\"profile_id\"]:\n",
    "        index.append(i)\n",
    "\n",
    "n_train = int(0.8 * len(index))\n",
    "is_train = X[\"profile_id\"] <= index[n_train]\n",
    "is_test = X[\"profile_id\"] > index[n_train]\n",
    "\n",
    "# conversion to numpy array\n",
    "X_train = X[is_train].drop([\"profile_id\"], axis=1).to_numpy()\n",
    "X_test = X[is_test].drop([\"profile_id\"], axis=1).to_numpy()\n",
    "y_train = y[is_train].to_numpy()\n",
    "y_test = y[is_test].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a toy model. We did not seek to obtain the most accurate model as this notebook is only intended for a proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[-1]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\")\n",
    "model.fit(X_train, y_train, batch_size=32, shuffle=True, validation_split=0.2, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Robustness to sensoir noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we detail how to derive upper \n",
    "and lower bounds on the output of a neural network given some noise on the input. \n",
    "Hence we are able to bound formally the worst case prediction given noise.\n",
    "In that order, we will use the [decomon](https://gheprivate.intra.corp/CRT-DataScience/decomon/tree/master/decomon) library. Decomon combines several optimization trick, including linear relaxation\n",
    "to get state-of-the-art outer approximation.\n",
    "\n",
    "To use **decomon** for **local robustness to sensor noise** we first need the following imports:\n",
    "+ *from decomon.models import clone*: to convert our current Keras model into another neural network nn_model. nn_model will output the same prediction that our model and adds extra information that will be used to derive our formal bounds. For a sake of clarity, how to get such bounds is hidden to the user, but an interested reader may refer to \n",
    "    \n",
    "    > _Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond._ NeurIPS 2020. Kaidi Xu*, Zhouxing Shi*, Huan Zhang*, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya Kailkhura, Xue Lin, Cho-Jui Hsieh (* Equal contribution).\n",
    "\n",
    "+ *from decomon import get_lower_noise, get_upper_noise, get_range_noise*: a generic method to get respectively a lower bound, an upper bound, or both on the prediction of a neural network in a $L_p$ (p $\\in \\{1, 2, \\infty\\} $) ball with radius epsilon around a sample. If the type of Lp norm is not provided, we assume that we consider a worst case noise independently on every input variable ($L_{\\infty}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decomon import get_lower_noise, get_range_noise, get_upper_noise\n",
    "from decomon.core import BallDomain\n",
    "from decomon.models import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise $L_{\\infty}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will first consider a worst case noise independently on every input variable ($L_{\\infty}$).\n",
    "We pick a random subset of the test dataset and compute an envelop of the network prediction with a noise epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can play with the magnitude of the noise\n",
    "epsilon = 1e-2\n",
    "\n",
    "# size of the subset of the test set\n",
    "n_rand = 1000\n",
    "# sampling from the test set\n",
    "index_rand = np.random.permutation(len(X_test))[:n_rand]\n",
    "X_rand = X_test[index_rand]\n",
    "y_pred = model.predict(X_rand, verbose=0)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **get_upper_noise** and **get_lower_noise methods** return upper and lower bounds over a batchs of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute formal bounds\n",
    "start_time = time.process_time()  # optional\n",
    "upper_test = get_upper_noise(model, X_rand, eps=epsilon, p=np.inf)[:, 0]\n",
    "lower_test = get_lower_noise(model, X_rand, eps=epsilon, p=np.inf)[:, 0]\n",
    "end_time = time.process_time()  # optional\n",
    "\n",
    "print(\"Average time to get an upper and a lower bound:{} s\".format((end_time - start_time) / n_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compute both bounds within a single call to the method **get_range_noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_test_bis, lower_test_bis = get_range_noise(model, X_rand, eps=epsilon, p=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assess that the output results remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(upper_test, upper_test_bis[:, 0], decimal=4, err_msg=\"error\")\n",
    "assert_almost_equal(lower_test, lower_test_bis[:, 0], decimal=4, err_msg=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to compute both upper and lower bounds or call those methods several time in your script, the most efficient way is to call the method on the decomon version itself. To do so, you first need to convert your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.process_time()  # optional\n",
    "perturbation_domain = BallDomain(p=np.inf, eps=epsilon)\n",
    "nn_model = clone(model, method=\"crown-forward-hybrid\", perturbation_domain=perturbation_domain)\n",
    "upper_test_ = get_upper_noise(nn_model, X_rand, eps=epsilon, p=np.inf)[:, 0]\n",
    "lower_test_ = get_lower_noise(nn_model, X_rand, eps=epsilon, p=np.inf)[:, 0]\n",
    "end_time = time.process_time()  # optional\n",
    "print(\"Average time to get an upper and a lower bound:{} s\".format((end_time - start_time) / n_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assess that the output results remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(upper_test, upper_test_, decimal=4, err_msg=\"error\")\n",
    "assert_almost_equal(lower_test, lower_test_, decimal=4, err_msg=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(y_pred), upper_test_[np.argsort(y_pred)], c=\"k\")\n",
    "plt.plot(np.sort(y_pred), lower_test_[np.argsort(y_pred)], c=\"b\")\n",
    "plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()], \"--\")\n",
    "plt.legend([\"upper>max NN(x+eps)\", \"lower<min NN(x+eps)\"])\n",
    "plt.xlabel(\"predicted temperature (t)\")\n",
    "plt.ylabel(\"formal bounds given a bounded noise: eps<={}\".format(epsilon))\n",
    "plt.title(\"Formal robustness in a box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise $L_{2}$\n",
    "\n",
    "Usually, sensor noise is approximated by Gaussian noise. One way to represent it with formal methods is to use an euclidian ball. We provide an illustration of how to express Gaussian noise in a 2D domain as a pink ball that covers the distribution with high probability.\n",
    "\n",
    "<img src=\"./data/ball_fm.png\" alt=\"ball_fm\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute formal bounds\n",
    "start_time = time.process_time()  # optional\n",
    "upper_test, lower_test = get_range_noise(model, X_rand, eps=epsilon, p=2)\n",
    "upper_test = upper_test[:, 0]\n",
    "lower_test = lower_test[:, 0]\n",
    "end_time = time.process_time()  # optional\n",
    "\n",
    "print(\"Average time to get an upper and a lower bound:{} s\".format((end_time - start_time) / n_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(y_pred), upper_test[np.argsort(y_pred)], c=\"k\")\n",
    "plt.plot(np.sort(y_pred), lower_test[np.argsort(y_pred)], c=\"b\")\n",
    "plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()], \"--\")\n",
    "plt.legend([\"upper>max NN(x+eps)\", \"lower<min NN(x+eps)\"])\n",
    "plt.xlabel(\"predicted temperature (t)\")\n",
    "plt.ylabel(\"formal bounds given a bounded noise: eps<={}\".format(epsilon))\n",
    "plt.title(\"Formal robustness in an euclidean ball\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
