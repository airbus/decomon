from typing import Any, Union

import keras
import keras.ops as K
import numpy as np
from keras import Model
from keras.utils import serialize_keras_object

from decomon.constants import ConvertMethod
from decomon.layers.output import ConvertOutput
from decomon.perturbation_domain import PerturbationDomain


class DecomonModel(keras.Model):
    """Decomon models computing constant and/or affine bounds on outputs of a keras model.

    This is the model generated by `decomon.clone()`.

    Inputs: perturbation_domain_inputs + backward_bounds with
        - perturbation_domain_inputs: peturbation domain input wrapped in a list
        - backward_bounds: the precomputed backward_bounds if the decomon model has been generated with it, empty else.

    Outputs: sum_{i} (affine_bounds[i] + constant_bounds[i]): the affine and constant bounds computed
        - affine_bounds_to[i]: affine bounds on i-th output of the keras model;
            empty if `self.affine` is False, else: w_l[i], b_l[i], w_u[i], b_u[i] so that

            x * w_l[i] + b_l[i] <= keras_model(x)[i] <= x * w_u[i] + b_u[i]

        - constant_bounds_to[i]: constant bounds on i-th output of the keras model;
            empty if `self.ibp` is False, else lower[i], upper[i] so that

            lower[i] <= keras_model(x)[i] <= upper[i]

    See `decomon.clone()` doc for more details on format.

    Args:



    """

    def __init__(
        self,
        inputs: Union[keras.KerasTensor, list[keras.KerasTensor]],
        outputs: Union[keras.KerasTensor, list[keras.KerasTensor]],
        perturbation_domain: PerturbationDomain,
        method: ConvertMethod,
        ibp: bool,
        affine: bool,
        model: Model,
        **kwargs: Any,
    ):
        """

        Args:
            inputs: inputs of the decomon model (perturbation domain input + optionally backward_bounds on a consecutive model)
            outputs: outputs of the decomon model
            perturbation_domain: perturbation domain type considered on keras model inputs
            method: conversion method
            ibp: outputing constant bounds?
            affine: outputing affine bounds?
            model: original keras model to bound
            **kwargs: passed to `keras.Model` constructor

        """
        super().__init__(inputs, outputs, **kwargs)
        self.model = model
        self.perturbation_domain = perturbation_domain
        self.method = method
        self.ibp = ibp
        self.affine = affine

    def get_config(self) -> dict[str, Any]:
        # force having functional config which is skipped by default
        # because DecomonModel.__init__() has not same signature as Functional.__init__()
        config = Model(self.inputs, self.outputs).get_config()
        # update with correct name + specific attributes of decomon model
        config.update(
            dict(
                name=self.name,
                perturbation_domain=serialize_keras_object(self.perturbation_domain),
                dc_decomp=self.dc_decomp,
                method=self.method,
                ibp=self.ibp,
                affine=self.affine,
                finetune=self.finetune,
                shared=self.shared,
                backward_bounds=self.backward_bounds,
            )
        )
        return config

    def set_domain(self, perturbation_domain: PerturbationDomain) -> None:
        perturbation_domain = _check_domain(self.perturbation_domain, perturbation_domain)
        self.perturbation_domain = perturbation_domain
        for layer in self.layers:
            if hasattr(layer, "perturbation_domain"):
                layer.perturbation_domain = self.perturbation_domain

    def predict_on_single_batch_np(
        self, inputs: Union[np.ndarray, list[np.ndarray]]
    ) -> Union[np.ndarray, list[np.ndarray]]:
        """Make predictions on numpy arrays fitting in one batch

        Avoid using `self.predict()` known to be not designed for small arrays,
        and leading to memory leaks when used in loops.

        See https://keras.io/api/models/model_training_apis/#predict-method and
        https://github.com/tensorflow/tensorflow/issues/44711

        Args:
            inputs:

        Returns:

        """
        output_tensors = self(inputs)
        if isinstance(output_tensors, list):
            return [K.convert_to_numpy(output) for output in output_tensors]
        else:
            return K.convert_to_numpy(output_tensors)

    def compute_constant_bounds_np(self, inputs: Union[np.ndarray, list[np.ndarray]]) -> list[np.ndarray]:
        """

        Args:
            inputs: perturbation_domain_inputs + backward_bounds, same format as `self.inputs`

        Returns:
            constant bounds: sum_{i} constant_bounds[i], constant bounds for each keras model output, concatenated
                with constant_bounds[i] = [lower[i], upper[i]]

        Notes:
            Constant bounds are
            - either directly computed as is (forward-ibp method)
            - or deduced from affine bounds (forward-affine or crown-* methods)
            - or chosen as tightest between both ibp and affine (forward-hybrid)

        """
        output_tensors = self(inputs)
        if not (self.ibp and not self.affine):
            convert_layer = ConvertOutput(
                ibp_from=self.ibp,
                affine_from=self.affine,
                ibp_to=True,
                affine_to=False,
                perturbation_domain=self.perturbation_domain,
                model_output_shapes=[t.shape[1:] for t in self.model.outputs],
            )
            if convert_layer.needs_perturbation_domain_inputs():
                if isinstance(inputs, np.ndarray):
                    perturbation_domain_input = inputs
                else:
                    perturbation_domain_input = inputs[0]
                output_tensors.append(perturbation_domain_input)
            # convert actual outputs
            output_tensors = convert_layer(output_tensors)
        return [K.convert_to_numpy(output) for output in output_tensors]

    def compute_affine_bounds_np(self, inputs: Union[np.ndarray, list[np.ndarray]]) -> list[np.ndarray]:
        """

        Args:
            inputs: perturbation_domain_inputs + backward_bounds, same format as `self.inputs`

        Returns:
            affine bounds: sum_{i} affine_bounds[i], affine bounds for each keras model output, concatenated
                with affine_bounds[i] = [w_l[i], b_l[i], w_u[i], b_u[i]]

        Notes:
            Affine bounds are
            - either directly computed as is (forward-affine or crown-* methods)
            - or deduced from constant bounds (forward-ibp method)

        """
        output_tensors = self(inputs)
        if not (self.affine and not self.ibp):
            convert_layer = ConvertOutput(
                ibp_from=self.ibp,
                affine_from=self.affine,
                ibp_to=False,
                affine_to=True,
                perturbation_domain=self.perturbation_domain,
                model_output_shapes=[t.shape[1:] for t in self.model.outputs],
            )
            if convert_layer.needs_perturbation_domain_inputs():
                if isinstance(inputs, np.ndarray):
                    perturbation_domain_input = inputs
                else:
                    perturbation_domain_input = inputs[0]
                output_tensors.append(perturbation_domain_input)
            # convert actual outputs
            output_tensors = convert_layer(output_tensors)
        return [K.convert_to_numpy(output) for output in output_tensors]


def _check_domain(
    perturbation_domain_prev: PerturbationDomain, perturbation_domain: PerturbationDomain
) -> PerturbationDomain:
    if type(perturbation_domain) != type(perturbation_domain_prev):
        raise NotImplementedError("We can only change the parameters of the perturbation domain, not its type.")

    return perturbation_domain
